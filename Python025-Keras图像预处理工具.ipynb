{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Input,Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "input_shape=(32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "# 数据增强\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 890,410\n",
      "Trainable params: 890,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    image_input=Input(shape=input_shape)\n",
    "    conv1=Conv2D(32,kernel_size=(3,3),activation='relu',padding='same')(image_input)\n",
    "    conv2=Conv2D(32,kernel_size=(3,3),activation='relu')(conv1)\n",
    "    pool1=MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "    pool1=Dropout(0.25)(pool1)\n",
    "    conv3=Conv2D(64, kernel_size=(3,3),activation='relu')(pool1)\n",
    "    conv4=Conv2D(64, kernel_size=(3,3),activation='relu')(conv3)\n",
    "    pool2=MaxPool2D(pool_size=(2, 2))(conv4)\n",
    "    pool2=Dropout(0.25)(pool2)\n",
    "    dense=Flatten()(pool2)\n",
    "    dense=Dense(512,activation='relu')(dense)\n",
    "    dense=Dropout(0.5)(dense)\n",
    "    preds=Dense(10, activation='softmax')(dense)\n",
    "    model=Model(image_input,preds)\n",
    "    model.compile(optimizer='rmsprop',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.6282 - accuracy: 0.4101\n",
      "Epoch 2/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.3043 - accuracy: 0.5412\n",
      "Epoch 3/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.1939 - accuracy: 0.5889\n",
      "Epoch 4/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.1426 - accuracy: 0.6099\n",
      "Epoch 5/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.1288 - accuracy: 0.6165\n",
      "Epoch 6/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.1443 - accuracy: 0.6182\n",
      "Epoch 7/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.1626 - accuracy: 0.6152\n",
      "Epoch 8/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.1961 - accuracy: 0.6076\n",
      "Epoch 9/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.2233 - accuracy: 0.5978\n",
      "Epoch 10/10\n",
      "1563/1562 [==============================] - 15s 10ms/step - loss: 1.2586 - accuracy: 0.5918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2dffe058908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "prediction=model.predict_generator(test_datagen.flow(x_test, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.58915725e-02, 2.48960897e-01, 1.79311857e-02, ...,\n",
       "        6.63576042e-03, 4.54858810e-01, 1.39545649e-01],\n",
       "       [8.52727983e-03, 7.83650130e-02, 8.82445544e-04, ...,\n",
       "        1.83691317e-03, 2.23307274e-02, 8.83106828e-01],\n",
       "       [3.32298204e-02, 2.32766028e-02, 9.27049071e-02, ...,\n",
       "        1.27313018e-01, 7.14371800e-02, 9.19944793e-02],\n",
       "       ...,\n",
       "       [7.71535560e-05, 4.56664784e-05, 2.25497782e-02, ...,\n",
       "        8.46468378e-04, 6.69107249e-04, 5.61139714e-05],\n",
       "       [7.91490136e-04, 4.86954639e-04, 1.27374172e-01, ...,\n",
       "        1.07564665e-01, 2.23355644e-04, 1.64540869e-03],\n",
       "       [3.39485168e-01, 8.31511840e-02, 5.49951307e-02, ...,\n",
       "        7.97751397e-02, 2.35293686e-01, 1.08191028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
