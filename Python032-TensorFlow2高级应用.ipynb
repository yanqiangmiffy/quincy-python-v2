{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考链接：\n",
    "- [5-4，模型层layers](https://www.kesci.com/home/project/5ea7d3b2564b12002c09dc57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义模型层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果自定义模型层没有需要被训练的参数，一般推荐使用Lamda层实现。\n",
    "\n",
    "如果自定义模型层有需要被训练的参数，则可以通过对Layer基类子类化实现。\n",
    "\n",
    "Lamda层由于没有需要被训练的参数，只需要定义正向传播逻辑即可，使用比Layer基类子类化更加简单。\n",
    "\n",
    "Lamda层的正向逻辑可以使用Python的lambda函数来表达，也可以用def关键字定义函数来表达。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,regularizers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0,  1,  4,  9, 16])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypower = layers.Lambda(lambda x:tf.math.pow(x,2))\n",
    "mypower(tf.range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer的子类化一般需要重新实现初始化方法，Build方法和Call方法。下面是一个简化的线性层的范例，类似Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(layers.Layer):\n",
    "    def __init__(self,units=32,**kwargs):\n",
    "        super(Linear,self).__init__(**kwargs)\n",
    "        self.units=units\n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(shape=(input_shape[-1],self.units),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True)\n",
    "        self.b=self.add_weight(shape=(self.units,),\n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "        super(Linear,self).build(input_shape)\n",
    "    def call(self,inputs):\n",
    "        \"\"\"\n",
    "        call方法一般定义定义正向1传播运算逻辑，__call__方法调用此方法\n",
    "        \"\"\"\n",
    "        return tf.matmul(inputs,self.w)+self.b\n",
    "    \n",
    "    def get_config(self):\n",
    "        config=super(Linear,self).get_config()\n",
    "        config.update({'units':self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(units = 8)\n",
    "print(linear.built)\n",
    "#指定input_shape，显式调用build方法，第0维代表样本数量，用None填充\n",
    "linear.build(input_shape = (None,16)) \n",
    "print(linear.built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(None, 8)\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(units = 8)\n",
    "print(linear.built)\n",
    "linear.build(input_shape = (None,16)) \n",
    "print(linear.compute_output_shape(input_shape = (None,16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "{'name': 'linear_2', 'trainable': True, 'dtype': 'float32', 'units': 16}\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(units = 16)\n",
    "print(linear.built)\n",
    "#如果built = False，调用__call__时会先调用build方法, 再调用call方法。\n",
    "linear(tf.random.uniform((100,64))) \n",
    "print(linear.built)\n",
    "config = linear.get_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.input_shape:  (None, 64)\n",
      "model.output_shape:  (None, 16)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "linear (Linear)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 1,040\n",
      "Trainable params: 1,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "#注意该处的input_shape会被模型加工，无需使用None代表样本数量维\n",
    "model.add(Linear(units = 16,input_shape = (64,)))  \n",
    "print(\"model.input_shape: \",model.input_shape)\n",
    "print(\"model.output_shape: \",model.output_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Linear at 0xdadb208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 查看参数名称\n",
    "linear = Linear(units = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 16), dtype=float32, numpy=\n",
       "array([[-0.04333059, -0.08049949, -0.03249026,  0.05443351, -0.07544892,\n",
       "        -0.08854784, -0.19290403, -0.01550727,  0.02320928,  0.2550611 ,\n",
       "        -0.15202959, -0.04553121, -0.07346585,  0.23583043,  0.03007973,\n",
       "        -0.06857169],\n",
       "       [-0.04333059, -0.08049949, -0.03249026,  0.05443351, -0.07544892,\n",
       "        -0.08854784, -0.19290403, -0.01550727,  0.02320928,  0.2550611 ,\n",
       "        -0.15202959, -0.04553121, -0.07346585,  0.23583043,  0.03007973,\n",
       "        -0.06857169],\n",
       "       [-0.04333059, -0.08049949, -0.03249026,  0.05443351, -0.07544892,\n",
       "        -0.08854784, -0.19290403, -0.01550727,  0.02320928,  0.2550611 ,\n",
       "        -0.15202959, -0.04553121, -0.07346585,  0.23583043,  0.03007973,\n",
       "        -0.06857169],\n",
       "       [-0.04333059, -0.08049949, -0.03249026,  0.05443351, -0.07544892,\n",
       "        -0.08854784, -0.19290403, -0.01550727,  0.02320928,  0.2550611 ,\n",
       "        -0.15202959, -0.04553121, -0.07346585,  0.23583043,  0.03007973,\n",
       "        -0.06857169],\n",
       "       [-0.04333059, -0.08049949, -0.03249026,  0.05443351, -0.07544892,\n",
       "        -0.08854784, -0.19290403, -0.01550727,  0.02320928,  0.2550611 ,\n",
       "        -0.15202959, -0.04553121, -0.07346585,  0.23583043,  0.03007973,\n",
       "        -0.06857169],\n",
       "       [-0.04333059, -0.08049949, -0.03249026,  0.05443351, -0.07544892,\n",
       "        -0.08854784, -0.19290403, -0.01550727,  0.02320928,  0.2550611 ,\n",
       "        -0.15202959, -0.04553121, -0.07346585,  0.23583043,  0.03007973,\n",
       "        -0.06857169]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(tf.ones([6, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'linear_2/Variable:0' shape=(5, 16) dtype=float32, numpy=\n",
       " array([[ 2.59076003e-02, -5.27851991e-02, -7.70981088e-02,\n",
       "          6.03635125e-02, -8.42469931e-02, -3.68040651e-02,\n",
       "         -3.97913111e-03, -9.20438543e-02, -7.15096444e-02,\n",
       "          3.81210484e-02,  1.47387898e-02, -2.99345609e-02,\n",
       "         -4.81296033e-02, -2.19797827e-02, -8.68842155e-02,\n",
       "         -4.15231250e-02],\n",
       "        [-4.94861379e-02, -4.48313765e-02,  5.66767342e-02,\n",
       "         -2.03403868e-02,  6.25559092e-02, -5.30785806e-02,\n",
       "         -4.56362963e-02,  3.68531793e-02,  4.89867106e-02,\n",
       "          1.23078756e-01,  2.56472686e-03,  3.13064791e-02,\n",
       "          5.30909076e-02,  9.74147115e-03, -1.73773952e-02,\n",
       "         -9.05219018e-02],\n",
       "        [ 5.86021207e-02,  2.76081054e-03,  5.44458888e-02,\n",
       "         -4.49273176e-02, -7.94086512e-03,  1.87071841e-02,\n",
       "         -6.47474825e-02,  3.93426083e-02, -1.52370557e-02,\n",
       "          5.12947813e-02, -3.37163918e-02, -4.54051122e-02,\n",
       "         -3.03274523e-02,  1.17994562e-01,  6.99623600e-02,\n",
       "          2.45674662e-02],\n",
       "        [-3.28279808e-02,  4.34030257e-02, -3.27464305e-02,\n",
       "         -3.96953188e-02, -8.36339816e-02,  2.04981472e-02,\n",
       "          3.35286036e-02, -4.54967283e-02,  5.79704344e-02,\n",
       "         -7.87496567e-03, -5.41598275e-02,  1.29174883e-03,\n",
       "         -2.66942452e-03,  3.89069021e-02,  5.29544428e-02,\n",
       "         -3.34424190e-02],\n",
       "        [-4.23720069e-02,  9.89221517e-05, -1.39249666e-02,\n",
       "          6.66002259e-02, -4.03520698e-03,  2.48271273e-03,\n",
       "         -7.04465732e-02,  1.27133671e-02, -3.00178118e-02,\n",
       "         -1.66556146e-02, -7.79153034e-02, -3.06718946e-02,\n",
       "         -1.84182823e-02,  5.79787269e-02,  2.40733903e-02,\n",
       "          6.52717277e-02]], dtype=float32)>,\n",
       " <tf.Variable 'linear_2/Variable:0' shape=(16,) dtype=float32, numpy=\n",
       " array([-0.00315418, -0.02914567, -0.01984337,  0.03243279,  0.04185222,\n",
       "        -0.04035324, -0.04162314,  0.03312416,  0.03301665,  0.06709707,\n",
       "        -0.00354158,  0.02788213, -0.027012  ,  0.03318855, -0.01264886,\n",
       "         0.00707657], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  自定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习模型中有很多是通过叠加不同的结构层组合而成的，如resnet的每个残差块就是“卷积+批标准化+残差连接”的组合。\n",
    "\n",
    "在tensorflow2中要创建一个包含多个网络层的的结构，一般继承与tf.keras.Model类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [1.653277   0.96290684 1.9400918  1.8662715  1.7643625  1.282055\n",
      "    1.5997902  2.1563993  2.1351726 ]]\n",
      "\n",
      "  [[2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [2.1565793  1.1436929  2.7448354  2.9193456  2.0856676  1.0356885\n",
      "    1.9981244  3.1337562  2.5819607 ]\n",
      "   [1.653277   0.96290684 1.9400918  1.8662715  1.7643625  1.282055\n",
      "    1.5997902  2.1563993  2.1351726 ]]\n",
      "\n",
      "  [[1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.2839696  1.3594263  1.3745403  1.2740523  1.3869934  1.3933866\n",
      "    1.4902698  1.4918461  1.2734289 ]\n",
      "   [1.1304615  0.9729458  1.1071637  1.0545454  1.2708325  1.1723717\n",
      "    1.2644163  1.1751804  1.2463044 ]]]], shape=(1, 3, 9, 9), dtype=float32)\n",
      "['resnet_block/conv2d/kernel:0', 'resnet_block/conv2d/bias:0', 'resnet_block/batch_normalization/gamma:0', 'resnet_block/batch_normalization/beta:0', 'resnet_block/conv2d_1/kernel:0', 'resnet_block/conv2d_1/bias:0', 'resnet_block/batch_normalization_1/gamma:0', 'resnet_block/batch_normalization_1/beta:0', 'resnet_block/conv2d_2/kernel:0', 'resnet_block/conv2d_2/bias:0', 'resnet_block/batch_normalization_2/gamma:0', 'resnet_block/batch_normalization_2/beta:0']\n"
     ]
    }
   ],
   "source": [
    "class ResnetBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "            super(ResnetBlock, self).__init__(name='resnet_block')\n",
    "\n",
    "            # 每个子层卷积核数\n",
    "            filter1, filter2, filter3 = filters\n",
    "\n",
    "            # 三个子层，每层1个卷积加一个批正则化\n",
    "            # 第一个子层， 1*1的卷积\n",
    "            self.conv1 = tf.keras.layers.Conv2D(filter1, (1,1))\n",
    "            self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "            # 第二个子层， 使用特点的kernel_size\n",
    "            self.conv2 = tf.keras.layers.Conv2D(filter2, kernel_size, padding='same')\n",
    "            self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "            # 第三个子层，1*1卷积\n",
    "            self.conv3 = tf.keras.layers.Conv2D(filter3, (1,1))\n",
    "            self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        # 堆叠每个子层\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training=training)\n",
    "\n",
    "        # 残差连接\n",
    "        x += inputs\n",
    "        outputs = tf.nn.relu(x)\n",
    "        return outputs\n",
    "resnetBlock = ResnetBlock(2, [6,4,9])\n",
    "# 数据测试\n",
    "print(resnetBlock(tf.ones([1,3,9,9])))\n",
    "# 查看网络中的变量名\n",
    "print([x.name for x in resnetBlock.trainable_variables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
