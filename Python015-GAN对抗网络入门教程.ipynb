{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "译：A Beginner's Guide to Generative Adversarial Networks (GANs) https://skymind.ai/wiki/generative-adversarial-network-gan\n",
    "\n",
    "## 1 GAN简介\n",
    "生成对抗网络（英语：Generative Adversarial Network，简称GAN）是非监督式学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。该方法由伊恩·古德费洛等人于2014年提出。生成对抗网络由一个生成网络与一个判别网络组成。生成网络从潜在空间（latent space）中随机取样作为输入，其输出结果需要尽量模仿训练集中的真实样本。判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。\n",
    "\n",
    "生成对抗网络常用于生成以假乱真的图片。此外，该方法还被用于生成影片、三维物体模型等。\n",
    "\n",
    "虽然生成对抗网络原先是为了无监督学习提出的，它也被证明对半监督学习、完全监督学习 、强化学习是有用的。\n",
    "\n",
    "![](https://skymind.ai/images/wiki/aipainter.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 生成与判别算法\n",
    "\n",
    "要理解GAN，你应该知道生成算法是如何工作的，但是在理解生成算法之前，将它们与判别算法进行对比可以加深理解。我们先看下什么事判别算法？\n",
    "\n",
    "判别算法试图对输入数据进行分类; 也就是说，给定数据实例的特征，它们预测该数据所属的标签或类别。\n",
    "\n",
    "\n",
    "例如，给定电子邮件中的所有单词（数据实例），判别算法可以预测该消息是spam(垃圾邮件)还是not_spam(非垃圾邮件)。 其中`spam`是标签之一，从电子邮件收集的单词包是构成输入数据的特征。 当以数学方式表达此问题时，标签称为y，并且要素称为x。公式p（y|x）用于表示“给定x条件下y发生的概率”，在这种情况下，它将转换为“在给定邮件所包含的字词情况下，电子邮件是垃圾邮件的概率”。\n",
    "\n",
    "因此，判别算法是将特征映射到标签，而生成算法恰恰在做相反的事情。生成算法试图预测给定某个标签下的特征，而不是预测给定某些特征的标签。\n",
    "\n",
    "生成算法试图回答的问题是：假设这封电子邮件是垃圾邮件，特征的分布或者概率是怎么样的？ 虽然判别模型关注y和x之间的关系，但是生成模型关心“你如何得到x。”生成算法是为了计算出（x | y），给出y条件下x发生的概率，或者说给出标签时，特征的概率。 （也就是说，生成算法也可以用作分类器。恰好它们不是对输入数据进行分类。）\n",
    "\n",
    "下面两句话将判别与生成区分开来：\n",
    "\n",
    "- 判别模型学习了类之间的界限\n",
    "- 生成模型模拟各个类的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 GANs原理\n",
    "\n",
    "\n",
    "GAN的基本原理其实非常简单，这里以生成图片为例进行说明。假设我们有两个网络，G（Generator）和D（Discriminator）。正如它的名字所暗示的那样，它们的功能分别是：一个神经网络，称为生成器，生成新的数据实例，而另一个神经网络，判别器，评估它们的真实性; 即判别器决定它所评测的每个数据实例是否属于实际训练数据集。\n",
    "\n",
    "G是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片，记做G(z)。\n",
    "D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D（x）代表x为真实图片的概率，如果为1，就代表100%是真实的图片，而输出为0，就代表不可能是真实的图片。\n",
    "在训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而D的目标就是尽量把G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。\n",
    "\n",
    "最后博弈的结果是什么？在最理想的状态下，G可以生成足以“以假乱真”的图片G(z)。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D(G(z)) = 0.5。\n",
    "\n",
    " reference：https://zhuanlan.zhihu.com/p/24767059\n",
    " \n",
    "以下是GAN大致步骤：\n",
    "\n",
    "- 生成器接收随机数并返回图像。\n",
    "- 将生成的图像与从真实数据集中获取的图像流一起馈送到判别器中。\n",
    "- 判别器接收真实和假图像并返回概率，0到1之间的数字，1表示真实性的预测，0表示假。\n",
    "![](https://skymind.ai/images/wiki/gan_schema.png)\n",
    "\n",
    "\n",
    "您可以将GAN视为诈骗者和警察在猫与老鼠游戏中的反对，其中诈骗者正在学习传递虚假信息，并且警察正在学习如何检测它们。 两者都是动态的; 也就是说，警察也在接受培训，每一方都在不断升级中学习对方的方法。\n",
    "\n",
    "\n",
    "对于MNIST数据集，判别器网络是标准卷积网络，可以对馈送给它的图像进行分类，二项分类器将图像标记为真实或伪造。 在某种意义上，生成器是反卷积网络：当标准卷积分类器采用图像并对其进行下采样以产生概率时，生成器采用随机噪声矢量并将其上采样到图像。 第一个通过下采样技术（如maxpooling）丢弃数据，第二个生成新数据。\n",
    "![](https://skymind.ai/images/wiki/GANs.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 GANs, Autoencoders and VAEs\n",
    "\n",
    "下面对生成性对抗网络与其他神经网络（例如自动编码器和变分自动编码器）进行比较。\n",
    "\n",
    "自动编码器将输入数据编码为矢量。它们创建原始数据的隐藏或压缩表示，在减少维数方面很有用; 也就是说，用作隐藏表示的向量将原始数据压缩为较少数量的突出维度。 自动编码器可以与所谓的解码器配对，允许您根据其隐藏的表示重建输入数据，就像使用受限制的Boltzmann机器一样。\n",
    "\n",
    "![](https://skymind.ai/images/wiki/autoencoder_schema.jpg)\n",
    "\n",
    "变分自动编码器是生成算法，其为编码输入数据添加额外约束，即隐藏表示被标准化。 变分自动编码器能够像自动编码器一样压缩数据并像GAN一样合成数据。 然而GAN可以更精细、细粒度的生成数据，VAE生成的图像往往更加模糊。 Deeplearning4j的例子包括自动编码器和变分自动编码器。（https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Keras 实现GAN\n",
    "https://github.com/eriklindernoren/Keras-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.735185, acc.: 46.88%] [G loss: 0.829077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [D loss: 0.590758, acc.: 71.88%] [G loss: 0.793450]\n",
      "2000 [D loss: 0.587990, acc.: 62.50%] [G loss: 0.956186]\n",
      "3000 [D loss: 0.644352, acc.: 59.38%] [G loss: 0.914777]\n",
      "4000 [D loss: 0.673936, acc.: 62.50%] [G loss: 0.971460]\n",
      "5000 [D loss: 0.759974, acc.: 53.12%] [G loss: 0.904706]\n",
      "6000 [D loss: 0.555306, acc.: 81.25%] [G loss: 0.835633]\n",
      "7000 [D loss: 0.674409, acc.: 62.50%] [G loss: 0.823623]\n",
      "8000 [D loss: 0.672854, acc.: 53.12%] [G loss: 0.863680]\n",
      "9000 [D loss: 0.743683, acc.: 46.88%] [G loss: 0.868321]\n",
      "10000 [D loss: 0.635190, acc.: 59.38%] [G loss: 0.854181]\n",
      "11000 [D loss: 0.700397, acc.: 56.25%] [G loss: 0.778778]\n",
      "12000 [D loss: 0.741978, acc.: 46.88%] [G loss: 0.813542]\n",
      "13000 [D loss: 0.760614, acc.: 46.88%] [G loss: 0.833507]\n",
      "14000 [D loss: 0.671199, acc.: 68.75%] [G loss: 0.853395]\n",
      "15000 [D loss: 0.676217, acc.: 62.50%] [G loss: 0.920993]\n",
      "16000 [D loss: 0.593898, acc.: 68.75%] [G loss: 0.889001]\n",
      "17000 [D loss: 0.724363, acc.: 50.00%] [G loss: 0.893431]\n",
      "18000 [D loss: 0.779740, acc.: 43.75%] [G loss: 0.853765]\n",
      "19000 [D loss: 0.642237, acc.: 59.38%] [G loss: 0.830348]\n",
      "20000 [D loss: 0.587237, acc.: 62.50%] [G loss: 0.876839]\n",
      "21000 [D loss: 0.645381, acc.: 62.50%] [G loss: 0.827465]\n",
      "22000 [D loss: 0.723597, acc.: 46.88%] [G loss: 0.862281]\n",
      "23000 [D loss: 0.671319, acc.: 65.62%] [G loss: 0.903444]\n",
      "24000 [D loss: 0.684801, acc.: 62.50%] [G loss: 0.807403]\n",
      "25000 [D loss: 0.737355, acc.: 43.75%] [G loss: 0.813877]\n",
      "26000 [D loss: 0.606201, acc.: 68.75%] [G loss: 0.802509]\n",
      "27000 [D loss: 0.711020, acc.: 56.25%] [G loss: 0.894887]\n",
      "28000 [D loss: 0.641023, acc.: 56.25%] [G loss: 0.856079]\n",
      "29000 [D loss: 0.696889, acc.: 46.88%] [G loss: 0.728626]\n"
     ]
    }
   ],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (100,)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Plot the progress\n",
    "            if epoch%1000==0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"data/gan/images/mnist_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, save_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到D的判别准确率最终在46%-56%之间，也就是说G网络生成的图片已经真假难分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 参考资料\n",
    "- GAN学习指南：从原理入门到制作生成Demo https://zhuanlan.zhihu.com/p/24767059\n",
    "- A Beginner's Guide to Generative Adversarial Networks (GANs) https://skymind.ai/wiki/generative-adversarial-network-gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
